# coding=utf-8
"""
TrendRadar ä¸»ç¨‹åº

çƒ­ç‚¹æ–°é—»èšåˆä¸åˆ†æå·¥å…·
æ”¯æŒ: python -m trendradar
"""

import argparse
import os
import re
import webbrowser
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import requests

from trendradar.context import AppContext
from trendradar import __version__
from trendradar.core import load_config
from trendradar.core.analyzer import convert_keyword_stats_to_platform_stats
from trendradar.crawler import DataFetcher
from trendradar.storage import convert_crawl_results_to_news_data
from trendradar.utils.time import DEFAULT_TIMEZONE, is_within_days, calculate_days_old
from trendradar.ai import AIAnalyzer, AIAnalysisResult


def _parse_version(version_str: str) -> Tuple[int, int, int]:
    """è§£æç‰ˆæœ¬å·å­—ç¬¦ä¸²ä¸ºå…ƒç»„"""
    try:
        parts = version_str.strip().split(".")
        if len(parts) >= 3:
            return int(parts[0]), int(parts[1]), int(parts[2])
        return 0, 0, 0
    except:
        return 0, 0, 0


def _compare_version(local: str, remote: str) -> str:
    """æ¯”è¾ƒç‰ˆæœ¬å·ï¼Œè¿”å›çŠ¶æ€æ–‡å­—"""
    local_tuple = _parse_version(local)
    remote_tuple = _parse_version(remote)

    if local_tuple < remote_tuple:
        return "âš ï¸ éœ€è¦æ›´æ–°"
    elif local_tuple > remote_tuple:
        return "ğŸ”® è¶…å‰ç‰ˆæœ¬"
    else:
        return "âœ… å·²æ˜¯æœ€æ–°"


def _fetch_remote_version(version_url: str, proxy_url: Optional[str] = None) -> Optional[str]:
    """è·å–è¿œç¨‹ç‰ˆæœ¬å·"""
    try:
        proxies = None
        if proxy_url:
            proxies = {"http": proxy_url, "https": proxy_url}

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "text/plain, */*",
            "Cache-Control": "no-cache",
        }

        response = requests.get(version_url, proxies=proxies, headers=headers, timeout=10)
        response.raise_for_status()
        return response.text.strip()
    except Exception as e:
        print(f"[ç‰ˆæœ¬æ£€æŸ¥] è·å–è¿œç¨‹ç‰ˆæœ¬å¤±è´¥: {e}")
        return None


def _parse_config_versions(content: str) -> Dict[str, str]:
    """è§£æé…ç½®æ–‡ä»¶ç‰ˆæœ¬å†…å®¹ä¸ºå­—å…¸"""
    versions = {}
    try:
        if not content:
            return versions
        for line in content.splitlines():
            line = line.strip()
            if not line or "=" not in line:
                continue
            name, version = line.split("=", 1)
            versions[name.strip()] = version.strip()
    except Exception as e:
        print(f"[ç‰ˆæœ¬æ£€æŸ¥] è§£æé…ç½®ç‰ˆæœ¬å¤±è´¥: {e}")
    return versions


def check_all_versions(
    version_url: str,
    configs_version_url: Optional[str] = None,
    proxy_url: Optional[str] = None
) -> Tuple[bool, Optional[str]]:
    """
    ç»Ÿä¸€ç‰ˆæœ¬æ£€æŸ¥ï¼šç¨‹åºç‰ˆæœ¬ + é…ç½®æ–‡ä»¶ç‰ˆæœ¬

    Args:
        version_url: è¿œç¨‹ç¨‹åºç‰ˆæœ¬æ£€æŸ¥ URL
        configs_version_url: è¿œç¨‹é…ç½®æ–‡ä»¶ç‰ˆæœ¬æ£€æŸ¥ URL (è¿”å›æ ¼å¼: filename=version)
        proxy_url: ä»£ç† URL

    Returns:
        (need_update, remote_version): ç¨‹åºæ˜¯å¦éœ€è¦æ›´æ–°åŠè¿œç¨‹ç‰ˆæœ¬å·
    """
    # è·å–è¿œç¨‹ç‰ˆæœ¬
    remote_version = _fetch_remote_version(version_url, proxy_url)

    # è·å–è¿œç¨‹é…ç½®ç‰ˆæœ¬ï¼ˆå¦‚æœæœ‰æä¾› URLï¼‰
    remote_config_versions = {}
    if configs_version_url:
        content = _fetch_remote_version(configs_version_url, proxy_url)
        if content:
            remote_config_versions = _parse_config_versions(content)

    print("=" * 60)
    print("ç‰ˆæœ¬æ£€æŸ¥")
    print("=" * 60)

    if remote_version:
        print(f"è¿œç¨‹ç¨‹åºç‰ˆæœ¬: {remote_version}")
    else:
        print("è¿œç¨‹ç¨‹åºç‰ˆæœ¬: è·å–å¤±è´¥")

    if configs_version_url:
        if remote_config_versions:
            print(f"è¿œç¨‹é…ç½®æ¸…å•: è·å–æˆåŠŸ ({len(remote_config_versions)} ä¸ªæ–‡ä»¶)")
        else:
            print("è¿œç¨‹é…ç½®æ¸…å•: è·å–å¤±è´¥æˆ–ä¸ºç©º")

    print("-" * 60)

    program_status = _compare_version(__version__, remote_version) if remote_version else "(æ— æ³•æ¯”è¾ƒ)"
    print(f"  ä¸»ç¨‹åºç‰ˆæœ¬: {__version__} {program_status}")

    config_files = [
        Path("config/config.yaml"),
        Path("config/frequency_words.txt"),
        Path("config/ai_analysis_prompt.txt"),
        Path("config/ai_translation_prompt.txt"),
    ]

    version_pattern = re.compile(r"Version:\s*(\d+\.\d+\.\d+)", re.IGNORECASE)

    for config_file in config_files:
        if not config_file.exists():
            print(f"  {config_file.name}: æ–‡ä»¶ä¸å­˜åœ¨")
            continue

        try:
            with open(config_file, "r", encoding="utf-8") as f:
                local_version = None
                for i, line in enumerate(f):
                    if i >= 20:
                        break
                    match = version_pattern.search(line)
                    if match:
                        local_version = match.group(1)
                        break

                # è·å–è¯¥æ–‡ä»¶çš„è¿œç¨‹ç‰ˆæœ¬
                target_remote_version = remote_config_versions.get(config_file.name)

                if local_version:
                    if target_remote_version:
                        status = _compare_version(local_version, target_remote_version)
                        print(f"  {config_file.name}: {local_version} {status}")
                    else:
                        print(f"  {config_file.name}: {local_version} (æœªæ‰¾åˆ°è¿œç¨‹ç‰ˆæœ¬)")
                else:
                    print(f"  {config_file.name}: æœªæ‰¾åˆ°æœ¬åœ°ç‰ˆæœ¬å·")
        except Exception as e:
            print(f"  {config_file.name}: è¯»å–å¤±è´¥ - {e}")

    print("=" * 60)

    # è¿”å›ç¨‹åºç‰ˆæœ¬çš„æ›´æ–°çŠ¶æ€
    if remote_version:
        need_update = _parse_version(__version__) < _parse_version(remote_version)
        return need_update, remote_version if need_update else None
    return False, None


# === ä¸»åˆ†æå™¨ ===
class NewsAnalyzer:
    """æ–°é—»åˆ†æå™¨"""

    # æ¨¡å¼ç­–ç•¥å®šä¹‰
    MODE_STRATEGIES = {
        "incremental": {
            "mode_name": "å¢é‡æ¨¡å¼",
            "description": "å¢é‡æ¨¡å¼ï¼ˆåªå…³æ³¨æ–°å¢æ–°é—»ï¼Œæ— æ–°å¢æ—¶ä¸æ¨é€ï¼‰",
            "report_type": "å¢é‡åˆ†æ",
            "should_send_notification": True,
        },
        "current": {
            "mode_name": "å½“å‰æ¦œå•æ¨¡å¼",
            "description": "å½“å‰æ¦œå•æ¨¡å¼ï¼ˆå½“å‰æ¦œå•åŒ¹é…æ–°é—» + æ–°å¢æ–°é—»åŒºåŸŸ + æŒ‰æ—¶æ¨é€ï¼‰",
            "report_type": "å½“å‰æ¦œå•",
            "should_send_notification": True,
        },
        "daily": {
            "mode_name": "å…¨å¤©æ±‡æ€»æ¨¡å¼",
            "description": "å…¨å¤©æ±‡æ€»æ¨¡å¼ï¼ˆæ‰€æœ‰åŒ¹é…æ–°é—» + æ–°å¢æ–°é—»åŒºåŸŸ + æŒ‰æ—¶æ¨é€ï¼‰",
            "report_type": "å…¨å¤©æ±‡æ€»",
            "should_send_notification": True,
        },
    }

    def __init__(self, config: Optional[Dict] = None):
        # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–åŠ è½½æ–°é…ç½®
        if config is None:
            print("æ­£åœ¨åŠ è½½é…ç½®...")
            config = load_config()
        print(f"TrendRadar v{__version__} é…ç½®åŠ è½½å®Œæˆ")
        print(f"ç›‘æ§å¹³å°æ•°é‡: {len(config['PLATFORMS'])}")
        print(f"æ—¶åŒº: {config.get('TIMEZONE', DEFAULT_TIMEZONE)}")

        # åˆ›å»ºåº”ç”¨ä¸Šä¸‹æ–‡
        self.ctx = AppContext(config)

        self.request_interval = self.ctx.config["REQUEST_INTERVAL"]
        self.report_mode = self.ctx.config["REPORT_MODE"]
        self.rank_threshold = self.ctx.rank_threshold
        self.is_github_actions = os.environ.get("GITHUB_ACTIONS") == "true"
        self.is_docker_container = self._detect_docker_environment()
        self.update_info = None
        self.proxy_url = None
        self._setup_proxy()
        self.data_fetcher = DataFetcher(self.proxy_url)

        # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼ˆä½¿ç”¨ AppContextï¼‰
        self._init_storage_manager()
        # æ³¨æ„ï¼šupdate_info ç”± main() å‡½æ•°è®¾ç½®ï¼Œé¿å…é‡å¤è¯·æ±‚è¿œç¨‹ç‰ˆæœ¬

    def _init_storage_manager(self) -> None:
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼ˆä½¿ç”¨ AppContextï¼‰"""
        # è·å–æ•°æ®ä¿ç•™å¤©æ•°ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
        env_retention = os.environ.get("STORAGE_RETENTION_DAYS", "").strip()
        if env_retention:
            # ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®
            self.ctx.config["STORAGE"]["RETENTION_DAYS"] = int(env_retention)

        self.storage_manager = self.ctx.get_storage_manager()
        print(f"å­˜å‚¨åç«¯: {self.storage_manager.backend_name}")

        retention_days = self.ctx.config.get("STORAGE", {}).get("RETENTION_DAYS", 0)
        if retention_days > 0:
            print(f"æ•°æ®ä¿ç•™å¤©æ•°: {retention_days} å¤©")

    def _detect_docker_environment(self) -> bool:
        """æ£€æµ‹æ˜¯å¦è¿è¡Œåœ¨ Docker å®¹å™¨ä¸­"""
        try:
            if os.environ.get("DOCKER_CONTAINER") == "true":
                return True

            if os.path.exists("/.dockerenv"):
                return True

            return False
        except Exception:
            return False

    def _should_open_browser(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰“å¼€æµè§ˆå™¨"""
        return not self.is_github_actions and not self.is_docker_container

    def _setup_proxy(self) -> None:
        """è®¾ç½®ä»£ç†é…ç½®"""
        if not self.is_github_actions and self.ctx.config["USE_PROXY"]:
            self.proxy_url = self.ctx.config["DEFAULT_PROXY"]
            print("æœ¬åœ°ç¯å¢ƒï¼Œä½¿ç”¨ä»£ç†")
        elif not self.is_github_actions and not self.ctx.config["USE_PROXY"]:
            print("æœ¬åœ°ç¯å¢ƒï¼Œæœªå¯ç”¨ä»£ç†")
        else:
            print("GitHub Actionsç¯å¢ƒï¼Œä¸ä½¿ç”¨ä»£ç†")

    def _set_update_info_from_config(self) -> None:
        """ä»å·²ç¼“å­˜çš„è¿œç¨‹ç‰ˆæœ¬è®¾ç½®æ›´æ–°ä¿¡æ¯ï¼ˆä¸å†é‡å¤è¯·æ±‚ï¼‰"""
        try:
            version_url = self.ctx.config.get("VERSION_CHECK_URL", "")
            if not version_url:
                return

            remote_version = _fetch_remote_version(version_url, self.proxy_url)
            if remote_version:
                need_update = _parse_version(__version__) < _parse_version(remote_version)
                if need_update:
                    self.update_info = {
                        "current_version": __version__,
                        "remote_version": remote_version,
                    }
        except Exception as e:
            print(f"ç‰ˆæœ¬æ£€æŸ¥å‡ºé”™: {e}")

    def _get_mode_strategy(self) -> Dict:
        """è·å–å½“å‰æ¨¡å¼çš„ç­–ç•¥é…ç½®"""
        return self.MODE_STRATEGIES.get(self.report_mode, self.MODE_STRATEGIES["daily"])

    def _has_notification_configured(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦é…ç½®äº†ä»»ä½•é€šçŸ¥æ¸ é“"""
        cfg = self.ctx.config
        return any(
            [
                cfg["FEISHU_WEBHOOK_URL"],
                cfg["DINGTALK_WEBHOOK_URL"],
                cfg["WEWORK_WEBHOOK_URL"],
                (cfg["TELEGRAM_BOT_TOKEN"] and cfg["TELEGRAM_CHAT_ID"]),
                (
                    cfg["EMAIL_FROM"]
                    and cfg["EMAIL_PASSWORD"]
                    and cfg["EMAIL_TO"]
                ),
                (cfg["NTFY_SERVER_URL"] and cfg["NTFY_TOPIC"]),
                cfg["BARK_URL"],
                cfg["SLACK_WEBHOOK_URL"],
                cfg["GENERIC_WEBHOOK_URL"],
            ]
        )

    def _has_valid_content(
        self, stats: List[Dict], new_titles: Optional[Dict] = None
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ–°é—»å†…å®¹"""
        if self.report_mode == "incremental":
            # å¢é‡æ¨¡å¼ï¼šåªè¦æœ‰åŒ¹é…çš„æ–°é—»å°±æ¨é€
            # count_word_frequency å·²ç»ç¡®ä¿åªå¤„ç†æ–°å¢çš„æ–°é—»ï¼ˆåŒ…æ‹¬å½“å¤©ç¬¬ä¸€æ¬¡çˆ¬å–çš„æƒ…å†µï¼‰
            has_matched_news = any(stat["count"] > 0 for stat in stats)
            return has_matched_news
        elif self.report_mode == "current":
            # currentæ¨¡å¼ï¼šåªè¦statsæœ‰å†…å®¹å°±è¯´æ˜æœ‰åŒ¹é…çš„æ–°é—»
            return any(stat["count"] > 0 for stat in stats)
        else:
            # å½“æ—¥æ±‡æ€»æ¨¡å¼ä¸‹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„é¢‘ç‡è¯æ–°é—»æˆ–æ–°å¢æ–°é—»
            has_matched_news = any(stat["count"] > 0 for stat in stats)
            has_new_news = bool(
                new_titles and any(len(titles) > 0 for titles in new_titles.values())
            )
            return has_matched_news or has_new_news

    def _prepare_ai_analysis_data(
        self,
        ai_mode: str,
        current_results: Optional[Dict] = None,
        current_id_to_name: Optional[Dict] = None,
    ) -> Tuple[List[Dict], Optional[Dict]]:
        """
        ä¸º AI åˆ†æå‡†å¤‡æŒ‡å®šæ¨¡å¼çš„æ•°æ®

        Args:
            ai_mode: AI åˆ†ææ¨¡å¼ (daily/current/incremental)
            current_results: å½“å‰æŠ“å–çš„ç»“æœï¼ˆç”¨äº incremental æ¨¡å¼ï¼‰
            current_id_to_name: å½“å‰çš„å¹³å°æ˜ å°„ï¼ˆç”¨äº incremental æ¨¡å¼ï¼‰

        Returns:
            Tuple[stats, id_to_name]: ç»Ÿè®¡æ•°æ®å’Œå¹³å°æ˜ å°„
        """
        try:
            word_groups, filter_words, global_filters = self.ctx.load_frequency_words()

            if ai_mode == "incremental":
                # incremental æ¨¡å¼ï¼šä½¿ç”¨å½“å‰æŠ“å–çš„æ•°æ®
                if not current_results or not current_id_to_name:
                    print("[AI] incremental æ¨¡å¼éœ€è¦å½“å‰æŠ“å–æ•°æ®ï¼Œä½†æœªæä¾›")
                    return [], None

                # å‡†å¤‡å½“å‰æ—¶é—´ä¿¡æ¯
                time_info = self.ctx.format_time()
                title_info = self._prepare_current_title_info(current_results, time_info)

                # æ£€æµ‹æ–°å¢æ ‡é¢˜
                new_titles = self.ctx.detect_new_titles(list(current_results.keys()))

                # ç»Ÿè®¡è®¡ç®—
                stats, _ = self.ctx.count_frequency(
                    current_results,
                    word_groups,
                    filter_words,
                    current_id_to_name,
                    title_info,
                    new_titles,
                    mode="incremental",
                    global_filters=global_filters,
                    quiet=True,
                )

                # å¦‚æœæ˜¯ platform æ¨¡å¼ï¼Œè½¬æ¢æ•°æ®ç»“æ„
                if self.ctx.display_mode == "platform" and stats:
                    stats = convert_keyword_stats_to_platform_stats(
                        stats,
                        self.ctx.weight_config,
                        self.ctx.rank_threshold,
                    )

                return stats, current_id_to_name

            elif ai_mode in ["daily", "current"]:
                # åŠ è½½å†å²æ•°æ®
                analysis_data = self._load_analysis_data(quiet=True)
                if not analysis_data:
                    print(f"[AI] æ— æ³•åŠ è½½å†å²æ•°æ®ç”¨äº {ai_mode} æ¨¡å¼åˆ†æ")
                    return [], None

                (
                    all_results,
                    id_to_name,
                    title_info,
                    new_titles,
                    _,
                    _,
                    _,
                ) = analysis_data

                # ç»Ÿè®¡è®¡ç®—
                stats, _ = self.ctx.count_frequency(
                    all_results,
                    word_groups,
                    filter_words,
                    id_to_name,
                    title_info,
                    new_titles,
                    mode=ai_mode,
                    global_filters=global_filters,
                    quiet=True,
                )

                # å¦‚æœæ˜¯ platform æ¨¡å¼ï¼Œè½¬æ¢æ•°æ®ç»“æ„
                if self.ctx.display_mode == "platform" and stats:
                    stats = convert_keyword_stats_to_platform_stats(
                        stats,
                        self.ctx.weight_config,
                        self.ctx.rank_threshold,
                    )

                return stats, id_to_name
            else:
                print(f"[AI] æœªçŸ¥çš„ AI æ¨¡å¼: {ai_mode}")
                return [], None

        except Exception as e:
            print(f"[AI] å‡†å¤‡ {ai_mode} æ¨¡å¼æ•°æ®æ—¶å‡ºé”™: {e}")
            if self.ctx.config.get("DEBUG", False):
                import traceback
                traceback.print_exc()
            return [], None

    def _run_ai_analysis(
        self,
        stats: List[Dict],
        rss_items: Optional[List[Dict]],
        mode: str,
        report_type: str,
        id_to_name: Optional[Dict],
        current_results: Optional[Dict] = None,
    ) -> Optional[AIAnalysisResult]:
        """æ‰§è¡Œ AI åˆ†æ"""
        analysis_config = self.ctx.config.get("AI_ANALYSIS", {})
        if not analysis_config.get("ENABLED", False):
            return None

        # AI åˆ†ææ—¶é—´çª—å£æ§åˆ¶
        analysis_window = analysis_config.get("ANALYSIS_WINDOW", {})
        if analysis_window.get("ENABLED", False):
            push_manager = self.ctx.create_push_manager()
            time_range_start = analysis_window["TIME_RANGE"]["START"]
            time_range_end = analysis_window["TIME_RANGE"]["END"]

            if not push_manager.is_in_time_range(time_range_start, time_range_end):
                now = self.ctx.get_time()
                print(
                    f"[AI] åˆ†æçª—å£æ§åˆ¶ï¼šå½“å‰æ—¶é—´ {now.strftime('%H:%M')} ä¸åœ¨åˆ†ææ—¶é—´çª—å£ {time_range_start}-{time_range_end} å†…ï¼Œè·³è¿‡ AI åˆ†æ"
                )
                return None

            if analysis_window.get("ONCE_PER_DAY", False):
                # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»è¿›è¡Œè¿‡ AI åˆ†æ
                if push_manager.storage_backend.has_ai_analyzed_today():
                    print(f"[AI] åˆ†æçª—å£æ§åˆ¶ï¼šä»Šå¤©å·²åˆ†æè¿‡ï¼Œè·³è¿‡æœ¬æ¬¡ AI åˆ†æ")
                    return None
                else:
                    print(f"[AI] åˆ†æçª—å£æ§åˆ¶ï¼šä»Šå¤©é¦–æ¬¡åˆ†æ")

        print("[AI] æ­£åœ¨è¿›è¡Œ AI åˆ†æ...")
        try:
            ai_config = self.ctx.config.get("AI", {})
            debug_mode = self.ctx.config.get("DEBUG", False)
            analyzer = AIAnalyzer(ai_config, analysis_config, self.ctx.get_time, debug=debug_mode)

            # ç¡®å®š AI åˆ†æä½¿ç”¨çš„æ¨¡å¼
            ai_mode_config = analysis_config.get("MODE", "follow_report")
            if ai_mode_config == "follow_report":
                # è·Ÿéšæ¨é€æŠ¥å‘Šæ¨¡å¼
                ai_mode = mode
                ai_stats = stats
                ai_id_to_name = id_to_name
            elif ai_mode_config in ["daily", "current", "incremental"]:
                # ä½¿ç”¨ç‹¬ç«‹é…ç½®çš„æ¨¡å¼ï¼Œéœ€è¦é‡æ–°å‡†å¤‡æ•°æ®
                ai_mode = ai_mode_config
                if ai_mode != mode:
                    print(f"[AI] ä½¿ç”¨ç‹¬ç«‹åˆ†ææ¨¡å¼: {ai_mode} (æ¨é€æ¨¡å¼: {mode})")
                    print(f"[AI] æ­£åœ¨å‡†å¤‡ {ai_mode} æ¨¡å¼çš„æ•°æ®...")

                    # æ ¹æ® AI æ¨¡å¼é‡æ–°å‡†å¤‡æ•°æ®
                    ai_stats, ai_id_to_name = self._prepare_ai_analysis_data(
                        ai_mode, current_results, id_to_name
                    )
                    if not ai_stats:
                        print(f"[AI] è­¦å‘Š: æ— æ³•å‡†å¤‡ {ai_mode} æ¨¡å¼çš„æ•°æ®ï¼Œå›é€€åˆ°æ¨é€æ¨¡å¼æ•°æ®")
                        ai_stats = stats
                        ai_id_to_name = id_to_name
                        ai_mode = mode
                else:
                    ai_stats = stats
                    ai_id_to_name = id_to_name
            else:
                # é…ç½®é”™è¯¯ï¼Œå›é€€åˆ°è·Ÿéšæ¨¡å¼
                print(f"[AI] è­¦å‘Š: æ— æ•ˆçš„ ai_analysis.mode é…ç½® '{ai_mode_config}'ï¼Œä½¿ç”¨æ¨é€æ¨¡å¼ '{mode}'")
                ai_mode = mode
                ai_stats = stats
                ai_id_to_name = id_to_name

            # æå–å¹³å°åˆ—è¡¨
            platforms = list(ai_id_to_name.values()) if ai_id_to_name else []

            # æå–å…³é”®è¯åˆ—è¡¨
            keywords = [s.get("word", "") for s in ai_stats if s.get("word")] if ai_stats else []

            # ç¡®å®šæŠ¥å‘Šç±»å‹
            if ai_mode != mode:
                # æ ¹æ® AI æ¨¡å¼ç¡®å®šæŠ¥å‘Šç±»å‹
                ai_report_type = {
                    "daily": "å½“æ—¥æ±‡æ€»",
                    "current": "å½“å‰æ¦œå•",
                    "incremental": "å¢é‡æ›´æ–°"
                }.get(ai_mode, report_type)
            else:
                ai_report_type = report_type

            result = analyzer.analyze(
                stats=ai_stats,
                rss_stats=rss_items,
                report_mode=ai_mode,
                report_type=ai_report_type,
                platforms=platforms,
                keywords=keywords,
            )

            # è®¾ç½® AI åˆ†æä½¿ç”¨çš„æ¨¡å¼
            if result.success:
                result.ai_mode = ai_mode
                if result.error:
                    # æˆåŠŸä½†æœ‰è­¦å‘Šï¼ˆå¦‚ JSON è§£æé—®é¢˜ä½†ä½¿ç”¨äº†åŸå§‹æ–‡æœ¬ï¼‰
                    print(f"[AI] åˆ†æå®Œæˆï¼ˆæœ‰è­¦å‘Š: {result.error}ï¼‰")
                else:
                    print("[AI] åˆ†æå®Œæˆ")

                # è®°å½• AI åˆ†æï¼ˆå¦‚æœå¯ç”¨äº† once_per_dayï¼‰
                if analysis_window.get("ENABLED", False) and analysis_window.get("ONCE_PER_DAY", False):
                    push_manager = self.ctx.create_push_manager()
                    push_manager.storage_backend.record_ai_analysis(ai_mode)
            else:
                print(f"[AI] åˆ†æå¤±è´¥: {result.error}")

            return result
        except Exception as e:
            import traceback
            error_type = type(e).__name__
            error_msg = str(e)
            # æˆªæ–­è¿‡é•¿çš„é”™è¯¯æ¶ˆæ¯
            if len(error_msg) > 200:
                error_msg = error_msg[:200] + "..."
            print(f"[AI] åˆ†æå‡ºé”™ ({error_type}): {error_msg}")
            # è¯¦ç»†é”™è¯¯æ—¥å¿—åˆ° stderr
            import sys
            print(f"[AI] è¯¦ç»†é”™è¯¯å †æ ˆ:", file=sys.stderr)
            traceback.print_exc(file=sys.stderr)
            return AIAnalysisResult(success=False, error=f"{error_type}: {error_msg}")

    def _load_analysis_data(
        self,
        quiet: bool = False,
    ) -> Optional[Tuple[Dict, Dict, Dict, Dict, List, List]]:
        """ç»Ÿä¸€çš„æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ï¼Œä½¿ç”¨å½“å‰ç›‘æ§å¹³å°åˆ—è¡¨è¿‡æ»¤å†å²æ•°æ®"""
        try:
            # è·å–å½“å‰é…ç½®çš„ç›‘æ§å¹³å°IDåˆ—è¡¨
            current_platform_ids = self.ctx.platform_ids
            if not quiet:
                print(f"å½“å‰ç›‘æ§å¹³å°: {current_platform_ids}")

            all_results, id_to_name, title_info = self.ctx.read_today_titles(
                current_platform_ids, quiet=quiet
            )

            if not all_results:
                print("æ²¡æœ‰æ‰¾åˆ°å½“å¤©çš„æ•°æ®")
                return None

            total_titles = sum(len(titles) for titles in all_results.values())
            if not quiet:
                print(f"è¯»å–åˆ° {total_titles} ä¸ªæ ‡é¢˜ï¼ˆå·²æŒ‰å½“å‰ç›‘æ§å¹³å°è¿‡æ»¤ï¼‰")

            new_titles = self.ctx.detect_new_titles(current_platform_ids, quiet=quiet)
            word_groups, filter_words, global_filters = self.ctx.load_frequency_words()

            return (
                all_results,
                id_to_name,
                title_info,
                new_titles,
                word_groups,
                filter_words,
                global_filters,
            )
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None

    def _prepare_current_title_info(self, results: Dict, time_info: str) -> Dict:
        """ä»å½“å‰æŠ“å–ç»“æœæ„å»ºæ ‡é¢˜ä¿¡æ¯"""
        title_info = {}
        for source_id, titles_data in results.items():
            title_info[source_id] = {}
            for title, title_data in titles_data.items():
                ranks = title_data.get("ranks", [])
                url = title_data.get("url", "")
                mobile_url = title_data.get("mobileUrl", "")

                title_info[source_id][title] = {
                    "first_time": time_info,
                    "last_time": time_info,
                    "count": 1,
                    "ranks": ranks,
                    "url": url,
                    "mobileUrl": mobile_url,
                }
        return title_info

    def _prepare_standalone_data(
        self,
        results: Dict,
        id_to_name: Dict,
        title_info: Optional[Dict] = None,
        rss_items: Optional[List[Dict]] = None,
    ) -> Optional[Dict]:
        """
        ä»åŸå§‹æ•°æ®ä¸­æå–ç‹¬ç«‹å±•ç¤ºåŒºæ•°æ®

        Args:
            results: åŸå§‹çˆ¬å–ç»“æœ {platform_id: {title: title_data}}
            id_to_name: å¹³å° ID åˆ°åç§°çš„æ˜ å°„
            title_info: æ ‡é¢˜å…ƒä¿¡æ¯ï¼ˆå«æ’åå†å²ã€æ—¶é—´ç­‰ï¼‰
            rss_items: RSS æ¡ç›®åˆ—è¡¨

        Returns:
            ç‹¬ç«‹å±•ç¤ºæ•°æ®å­—å…¸ï¼Œå¦‚æœæœªå¯ç”¨è¿”å› None
        """
        display_config = self.ctx.config.get("DISPLAY", {})
        regions = display_config.get("REGIONS", {})
        standalone_config = display_config.get("STANDALONE", {})

        if not regions.get("STANDALONE", False):
            return None

        platform_ids = standalone_config.get("PLATFORMS", [])
        rss_feed_ids = standalone_config.get("RSS_FEEDS", [])
        max_items = standalone_config.get("MAX_ITEMS", 20)

        if not platform_ids and not rss_feed_ids:
            return None

        standalone_data = {
            "platforms": [],
            "rss_feeds": [],
        }

        # æ‰¾å‡ºæœ€æ–°æ‰¹æ¬¡æ—¶é—´ï¼ˆç±»ä¼¼ current æ¨¡å¼çš„è¿‡æ»¤é€»è¾‘ï¼‰
        latest_time = None
        if title_info:
            for source_titles in title_info.values():
                for title_data in source_titles.values():
                    last_time = title_data.get("last_time", "")
                    if last_time:
                        if latest_time is None or last_time > latest_time:
                            latest_time = last_time

        # æå–çƒ­æ¦œå¹³å°æ•°æ®
        for platform_id in platform_ids:
            if platform_id not in results:
                continue

            platform_name = id_to_name.get(platform_id, platform_id)
            platform_titles = results[platform_id]

            items = []
            for title, title_data in platform_titles.items():
                # è·å–å…ƒä¿¡æ¯ï¼ˆå¦‚æœæœ‰ title_infoï¼‰
                meta = {}
                if title_info and platform_id in title_info and title in title_info[platform_id]:
                    meta = title_info[platform_id][title]

                # åªä¿ç•™å½“å‰åœ¨æ¦œçš„è¯é¢˜ï¼ˆlast_time ç­‰äºæœ€æ–°æ—¶é—´ï¼‰
                if latest_time and meta:
                    if meta.get("last_time") != latest_time:
                        continue

                # ä½¿ç”¨å½“å‰çƒ­æ¦œçš„æ’åæ•°æ®ï¼ˆtitle_dataï¼‰è¿›è¡Œæ’åº
                # title_data åŒ…å«çš„æ˜¯çˆ¬è™«è¿”å›çš„å½“å‰æ’åï¼Œç”¨äºä¿è¯ç‹¬ç«‹å±•ç¤ºåŒºçš„é¡ºåºä¸çƒ­æ¦œä¸€è‡´
                current_ranks = title_data.get("ranks", [])
                current_rank = current_ranks[-1] if current_ranks else 0

                # ç”¨äºæ˜¾ç¤ºçš„æ’åèŒƒå›´ï¼šåˆå¹¶å†å²æ’åå’Œå½“å‰æ’å
                historical_ranks = meta.get("ranks", []) if meta else []
                # åˆå¹¶å»é‡ï¼Œä¿æŒé¡ºåº
                all_ranks = historical_ranks.copy()
                for rank in current_ranks:
                    if rank not in all_ranks:
                        all_ranks.append(rank)
                display_ranks = all_ranks if all_ranks else current_ranks

                item = {
                    "title": title,
                    "url": title_data.get("url", ""),
                    "mobileUrl": title_data.get("mobileUrl", ""),
                    "rank": current_rank,  # ç”¨äºæ’åºçš„å½“å‰æ’å
                    "ranks": display_ranks,  # ç”¨äºæ˜¾ç¤ºçš„æ’åèŒƒå›´ï¼ˆå†å²+å½“å‰ï¼‰
                    "first_time": meta.get("first_time", ""),
                    "last_time": meta.get("last_time", ""),
                    "count": meta.get("count", 1),
                }
                items.append(item)

            # æŒ‰å½“å‰æ’åæ’åº
            items.sort(key=lambda x: x["rank"] if x["rank"] > 0 else 9999)

            # é™åˆ¶æ¡æ•°
            if max_items > 0:
                items = items[:max_items]

            if items:
                standalone_data["platforms"].append({
                    "id": platform_id,
                    "name": platform_name,
                    "items": items,
                })

        # æå– RSS æ•°æ®
        if rss_items and rss_feed_ids:
            # æŒ‰ feed_id åˆ†ç»„
            feed_items_map = {}
            for item in rss_items:
                feed_id = item.get("feed_id", "")
                if feed_id in rss_feed_ids:
                    if feed_id not in feed_items_map:
                        feed_items_map[feed_id] = {
                            "name": item.get("feed_name", feed_id),
                            "items": [],
                        }
                    feed_items_map[feed_id]["items"].append({
                        "title": item.get("title", ""),
                        "url": item.get("url", ""),
                        "published_at": item.get("published_at", ""),
                        "author": item.get("author", ""),
                    })

            # é™åˆ¶æ¡æ•°å¹¶æ·»åŠ åˆ°ç»“æœ
            for feed_id in rss_feed_ids:
                if feed_id in feed_items_map:
                    feed_data = feed_items_map[feed_id]
                    items = feed_data["items"]
                    if max_items > 0:
                        items = items[:max_items]
                    if items:
                        standalone_data["rss_feeds"].append({
                            "id": feed_id,
                            "name": feed_data["name"],
                            "items": items,
                        })

        # å¦‚æœæ²¡æœ‰ä»»ä½•æ•°æ®ï¼Œè¿”å› None
        if not standalone_data["platforms"] and not standalone_data["rss_feeds"]:
            return None

        return standalone_data

    def _run_analysis_pipeline(
        self,
        data_source: Dict,
        mode: str,
        title_info: Dict,
        new_titles: Dict,
        word_groups: List[Dict],
        filter_words: List[str],
        id_to_name: Dict,
        failed_ids: Optional[List] = None,
        global_filters: Optional[List[str]] = None,
        quiet: bool = False,
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
        standalone_data: Optional[Dict] = None,
    ) -> Tuple[List[Dict], Optional[str], Optional[AIAnalysisResult]]:
        """ç»Ÿä¸€çš„åˆ†ææµæ°´çº¿ï¼šæ•°æ®å¤„ç† â†’ ç»Ÿè®¡è®¡ç®— â†’ AIåˆ†æ â†’ HTMLç”Ÿæˆ"""

        # ç»Ÿè®¡è®¡ç®—ï¼ˆä½¿ç”¨ AppContextï¼‰
        stats, total_titles = self.ctx.count_frequency(
            data_source,
            word_groups,
            filter_words,
            id_to_name,
            title_info,
            new_titles,
            mode=mode,
            global_filters=global_filters,
            quiet=quiet,
        )

        # å¦‚æœæ˜¯ platform æ¨¡å¼ï¼Œè½¬æ¢æ•°æ®ç»“æ„
        if self.ctx.display_mode == "platform" and stats:
            stats = convert_keyword_stats_to_platform_stats(
                stats,
                self.ctx.weight_config,
                self.ctx.rank_threshold,
            )

        # AI åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼Œç”¨äº HTML æŠ¥å‘Šï¼‰
        ai_result = None
        ai_config = self.ctx.config.get("AI_ANALYSIS", {})
        if ai_config.get("ENABLED", False) and stats:
            # è·å–æ¨¡å¼ç­–ç•¥æ¥ç¡®å®šæŠ¥å‘Šç±»å‹
            mode_strategy = self._get_mode_strategy()
            report_type = mode_strategy["report_type"]
            ai_result = self._run_ai_analysis(
                stats, rss_items, mode, report_type, id_to_name, current_results=data_source
            )

        # HTMLç”Ÿæˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
        html_file = None
        if self.ctx.config["STORAGE"]["FORMATS"]["HTML"]:
            html_file = self.ctx.generate_html(
                stats,
                total_titles,
                failed_ids=failed_ids,
                new_titles=new_titles,
                id_to_name=id_to_name,
                mode=mode,
                update_info=self.update_info if self.ctx.config["SHOW_VERSION_UPDATE"] else None,
                rss_items=rss_items,
                rss_new_items=rss_new_items,
                ai_analysis=ai_result,
                standalone_data=standalone_data,
            )

        return stats, html_file, ai_result

    def _send_notification_if_needed(
        self,
        stats: List[Dict],
        report_type: str,
        mode: str,
        failed_ids: Optional[List] = None,
        new_titles: Optional[Dict] = None,
        id_to_name: Optional[Dict] = None,
        html_file_path: Optional[str] = None,
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
        standalone_data: Optional[Dict] = None,
        ai_result: Optional[AIAnalysisResult] = None,
        current_results: Optional[Dict] = None,
    ) -> bool:
        """ç»Ÿä¸€çš„é€šçŸ¥å‘é€é€»è¾‘ï¼ŒåŒ…å«æ‰€æœ‰åˆ¤æ–­æ¡ä»¶ï¼Œæ”¯æŒçƒ­æ¦œ+RSSåˆå¹¶æ¨é€+AIåˆ†æ+ç‹¬ç«‹å±•ç¤ºåŒº"""
        has_notification = self._has_notification_configured()
        cfg = self.ctx.config

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹ï¼ˆçƒ­æ¦œæˆ–RSSï¼‰
        has_news_content = self._has_valid_content(stats, new_titles)
        has_rss_content = bool(rss_items and len(rss_items) > 0)
        has_any_content = has_news_content or has_rss_content

        # è®¡ç®—çƒ­æ¦œåŒ¹é…æ¡æ•°
        news_count = sum(len(stat.get("titles", [])) for stat in stats) if stats else 0
        # rss_items æ˜¯ç»Ÿè®¡åˆ—è¡¨ [{"word": "xx", "count": 5, ...}]ï¼Œéœ€ç´¯åŠ  count
        rss_count = sum(stat.get("count", 0) for stat in rss_items) if rss_items else 0

        if (
            cfg["ENABLE_NOTIFICATION"]
            and has_notification
            and has_any_content
        ):
            # è¾“å‡ºæ¨é€å†…å®¹ç»Ÿè®¡
            content_parts = []
            if news_count > 0:
                content_parts.append(f"çƒ­æ¦œ {news_count} æ¡")
            if rss_count > 0:
                content_parts.append(f"RSS {rss_count} æ¡")
            total_count = news_count + rss_count
            print(f"[æ¨é€] å‡†å¤‡å‘é€ï¼š{' + '.join(content_parts)}ï¼Œåˆè®¡ {total_count} æ¡")

            # æ¨é€çª—å£æ§åˆ¶
            if cfg["PUSH_WINDOW"]["ENABLED"]:
                push_manager = self.ctx.create_push_manager()
                time_range_start = cfg["PUSH_WINDOW"]["TIME_RANGE"]["START"]
                time_range_end = cfg["PUSH_WINDOW"]["TIME_RANGE"]["END"]

                if not push_manager.is_in_time_range(time_range_start, time_range_end):
                    now = self.ctx.get_time()
                    print(
                        f"æ¨é€çª—å£æ§åˆ¶ï¼šå½“å‰æ—¶é—´ {now.strftime('%H:%M')} ä¸åœ¨æ¨é€æ—¶é—´çª—å£ {time_range_start}-{time_range_end} å†…ï¼Œè·³è¿‡æ¨é€"
                    )
                    return False

                if cfg["PUSH_WINDOW"]["ONCE_PER_DAY"]:
                    if push_manager.has_pushed_today():
                        print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©å·²æ¨é€è¿‡ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                        return False
                    else:
                        print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©é¦–æ¬¡æ¨é€")

            # AI åˆ†æï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ç»“æœï¼Œé¿å…é‡å¤åˆ†æ
            if ai_result is None:
                ai_config = cfg.get("AI_ANALYSIS", {})
                if ai_config.get("ENABLED", False):
                    ai_result = self._run_ai_analysis(
                        stats, rss_items, mode, report_type, id_to_name, current_results=current_results
                    )

            # å‡†å¤‡æŠ¥å‘Šæ•°æ®
            report_data = self.ctx.prepare_report(stats, failed_ids, new_titles, id_to_name, mode)

            # æ˜¯å¦å‘é€ç‰ˆæœ¬æ›´æ–°ä¿¡æ¯
            update_info_to_send = self.update_info if cfg["SHOW_VERSION_UPDATE"] else None

            # ä½¿ç”¨ NotificationDispatcher å‘é€åˆ°æ‰€æœ‰æ¸ é“ï¼ˆåˆå¹¶çƒ­æ¦œ+RSS+AIåˆ†æ+ç‹¬ç«‹å±•ç¤ºåŒºï¼‰
            dispatcher = self.ctx.create_notification_dispatcher()
            results = dispatcher.dispatch_all(
                report_data=report_data,
                report_type=report_type,
                update_info=update_info_to_send,
                proxy_url=self.proxy_url,
                mode=mode,
                html_file_path=html_file_path,
                rss_items=rss_items,
                rss_new_items=rss_new_items,
                ai_analysis=ai_result,
                standalone_data=standalone_data,
            )

            if not results:
                print("æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ï¼Œè·³è¿‡é€šçŸ¥å‘é€")
                return False

            # å¦‚æœæˆåŠŸå‘é€äº†ä»»ä½•é€šçŸ¥ï¼Œä¸”å¯ç”¨äº†æ¯å¤©åªæ¨ä¸€æ¬¡ï¼Œåˆ™è®°å½•æ¨é€
            if (
                cfg["PUSH_WINDOW"]["ENABLED"]
                and cfg["PUSH_WINDOW"]["ONCE_PER_DAY"]
                and any(results.values())
            ):
                push_manager = self.ctx.create_push_manager()
                push_manager.record_push(report_type)

            return True

        elif cfg["ENABLE_NOTIFICATION"] and not has_notification:
            print("âš ï¸ è­¦å‘Šï¼šé€šçŸ¥åŠŸèƒ½å·²å¯ç”¨ä½†æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ï¼Œå°†è·³è¿‡é€šçŸ¥å‘é€")
        elif not cfg["ENABLE_NOTIFICATION"]:
            print(f"è·³è¿‡{report_type}é€šçŸ¥ï¼šé€šçŸ¥åŠŸèƒ½å·²ç¦ç”¨")
        elif (
            cfg["ENABLE_NOTIFICATION"]
            and has_notification
            and not has_any_content
        ):
            mode_strategy = self._get_mode_strategy()
            if self.report_mode == "incremental":
                if not has_rss_content:
                    print("è·³è¿‡é€šçŸ¥ï¼šå¢é‡æ¨¡å¼ä¸‹æœªæ£€æµ‹åˆ°åŒ¹é…çš„æ–°é—»å’ŒRSS")
                else:
                    print("è·³è¿‡é€šçŸ¥ï¼šå¢é‡æ¨¡å¼ä¸‹æ–°é—»æœªåŒ¹é…åˆ°å…³é”®è¯")
            else:
                print(
                    f"è·³è¿‡é€šçŸ¥ï¼š{mode_strategy['mode_name']}ä¸‹æœªæ£€æµ‹åˆ°åŒ¹é…çš„æ–°é—»"
                )

        return False

    def _initialize_and_check_config(self) -> None:
        """é€šç”¨åˆå§‹åŒ–å’Œé…ç½®æ£€æŸ¥"""
        now = self.ctx.get_time()
        print(f"å½“å‰åŒ—äº¬æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}")

        if not self.ctx.config["ENABLE_CRAWLER"]:
            print("çˆ¬è™«åŠŸèƒ½å·²ç¦ç”¨ï¼ˆENABLE_CRAWLER=Falseï¼‰ï¼Œç¨‹åºé€€å‡º")
            return

        has_notification = self._has_notification_configured()
        if not self.ctx.config["ENABLE_NOTIFICATION"]:
            print("é€šçŸ¥åŠŸèƒ½å·²ç¦ç”¨ï¼ˆENABLE_NOTIFICATION=Falseï¼‰ï¼Œå°†åªè¿›è¡Œæ•°æ®æŠ“å–")
        elif not has_notification:
            print("æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ï¼Œå°†åªè¿›è¡Œæ•°æ®æŠ“å–ï¼Œä¸å‘é€é€šçŸ¥")
        else:
            print("é€šçŸ¥åŠŸèƒ½å·²å¯ç”¨ï¼Œå°†å‘é€é€šçŸ¥")

        mode_strategy = self._get_mode_strategy()
        print(f"æŠ¥å‘Šæ¨¡å¼: {self.report_mode}")
        print(f"è¿è¡Œæ¨¡å¼: {mode_strategy['description']}")

    def _crawl_data(self) -> Tuple[Dict, Dict, List]:
        """æ‰§è¡Œæ•°æ®çˆ¬å–"""
        ids = []
        for platform in self.ctx.platforms:
            if "name" in platform:
                ids.append((platform["id"], platform["name"]))
            else:
                ids.append(platform["id"])

        print(
            f"é…ç½®çš„ç›‘æ§å¹³å°: {[p.get('name', p['id']) for p in self.ctx.platforms]}"
        )
        print(f"å¼€å§‹çˆ¬å–æ•°æ®ï¼Œè¯·æ±‚é—´éš” {self.request_interval} æ¯«ç§’")
        Path("output").mkdir(parents=True, exist_ok=True)

        results, id_to_name, failed_ids = self.data_fetcher.crawl_websites(
            ids, self.request_interval
        )

        # è½¬æ¢ä¸º NewsData æ ¼å¼å¹¶ä¿å­˜åˆ°å­˜å‚¨åç«¯
        crawl_time = self.ctx.format_time()
        crawl_date = self.ctx.format_date()
        news_data = convert_crawl_results_to_news_data(
            results, id_to_name, failed_ids, crawl_time, crawl_date
        )

        # ä¿å­˜åˆ°å­˜å‚¨åç«¯ï¼ˆSQLiteï¼‰
        if self.storage_manager.save_news_data(news_data):
            print(f"æ•°æ®å·²ä¿å­˜åˆ°å­˜å‚¨åç«¯: {self.storage_manager.backend_name}")

        # ä¿å­˜ TXT å¿«ç…§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        txt_file = self.storage_manager.save_txt_snapshot(news_data)
        if txt_file:
            print(f"TXT å¿«ç…§å·²ä¿å­˜: {txt_file}")

        # å…¼å®¹ï¼šåŒæ—¶ä¿å­˜åˆ°åŸæœ‰ TXT æ ¼å¼ï¼ˆç¡®ä¿å‘åå…¼å®¹ï¼‰
        if self.ctx.config["STORAGE"]["FORMATS"]["TXT"]:
            title_file = self.ctx.save_titles(results, id_to_name, failed_ids)
            print(f"æ ‡é¢˜å·²ä¿å­˜åˆ°: {title_file}")

        return results, id_to_name, failed_ids

    def _crawl_rss_data(self) -> Tuple[Optional[List[Dict]], Optional[List[Dict]], Optional[List[Dict]]]:
        """
        æ‰§è¡Œ RSS æ•°æ®æŠ“å–

        Returns:
            (rss_items, rss_new_items, raw_rss_items) å…ƒç»„ï¼š
            - rss_items: ç»Ÿè®¡æ¡ç›®åˆ—è¡¨ï¼ˆæŒ‰æ¨¡å¼å¤„ç†ï¼Œç”¨äºç»Ÿè®¡åŒºå—ï¼‰
            - rss_new_items: æ–°å¢æ¡ç›®åˆ—è¡¨ï¼ˆç”¨äºæ–°å¢åŒºå—ï¼‰
            - raw_rss_items: åŸå§‹ RSS æ¡ç›®åˆ—è¡¨ï¼ˆç”¨äºç‹¬ç«‹å±•ç¤ºåŒºï¼‰
            å¦‚æœæœªå¯ç”¨æˆ–å¤±è´¥è¿”å› (None, None, None)
        """
        if not self.ctx.rss_enabled:
            return None, None, None

        rss_feeds = self.ctx.rss_feeds
        if not rss_feeds:
            print("[RSS] æœªé…ç½®ä»»ä½• RSS æº")
            return None, None, None

        try:
            from trendradar.crawler.rss import RSSFetcher, RSSFeedConfig

            # æ„å»º RSS æºé…ç½®
            feeds = []
            for feed_config in rss_feeds:
                # è¯»å–å¹¶éªŒè¯å•ä¸ª feed çš„ max_age_daysï¼ˆå¯é€‰ï¼‰
                max_age_days_raw = feed_config.get("max_age_days")
                max_age_days = None
                if max_age_days_raw is not None:
                    try:
                        max_age_days = int(max_age_days_raw)
                        if max_age_days < 0:
                            feed_id = feed_config.get("id", "unknown")
                            print(f"[è­¦å‘Š] RSS feed '{feed_id}' çš„ max_age_days ä¸ºè´Ÿæ•°ï¼Œå°†ä½¿ç”¨å…¨å±€é»˜è®¤å€¼")
                            max_age_days = None
                    except (ValueError, TypeError):
                        feed_id = feed_config.get("id", "unknown")
                        print(f"[è­¦å‘Š] RSS feed '{feed_id}' çš„ max_age_days æ ¼å¼é”™è¯¯ï¼š{max_age_days_raw}")
                        max_age_days = None

                feed = RSSFeedConfig(
                    id=feed_config.get("id", ""),
                    name=feed_config.get("name", ""),
                    url=feed_config.get("url", ""),
                    max_items=feed_config.get("max_items", 50),
                    enabled=feed_config.get("enabled", True),
                    max_age_days=max_age_days,  # None=ä½¿ç”¨å…¨å±€ï¼Œ0=ç¦ç”¨ï¼Œ>0=è¦†ç›–
                )
                if feed.id and feed.url and feed.enabled:
                    feeds.append(feed)

            if not feeds:
                print("[RSS] æ²¡æœ‰å¯ç”¨çš„ RSS æº")
                return None, None, None

            # åˆ›å»ºæŠ“å–å™¨
            rss_config = self.ctx.rss_config
            # RSS ä»£ç†ï¼šä¼˜å…ˆä½¿ç”¨ RSS ä¸“å±ä»£ç†ï¼Œå¦åˆ™ä½¿ç”¨çˆ¬è™«é»˜è®¤ä»£ç†
            rss_proxy_url = rss_config.get("PROXY_URL", "") or self.proxy_url or ""
            # è·å–é…ç½®çš„æ—¶åŒº
            timezone = self.ctx.config.get("TIMEZONE", DEFAULT_TIMEZONE)
            # è·å–æ–°é²œåº¦è¿‡æ»¤é…ç½®
            freshness_config = rss_config.get("FRESHNESS_FILTER", {})
            freshness_enabled = freshness_config.get("ENABLED", True)
            default_max_age_days = freshness_config.get("MAX_AGE_DAYS", 3)

            fetcher = RSSFetcher(
                feeds=feeds,
                request_interval=rss_config.get("REQUEST_INTERVAL", 2000),
                timeout=rss_config.get("TIMEOUT", 15),
                use_proxy=rss_config.get("USE_PROXY", False),
                proxy_url=rss_proxy_url,
                timezone=timezone,
                freshness_enabled=freshness_enabled,
                default_max_age_days=default_max_age_days,
            )

            # æŠ“å–æ•°æ®
            rss_data = fetcher.fetch_all()

            # ä¿å­˜åˆ°å­˜å‚¨åç«¯
            if self.storage_manager.save_rss_data(rss_data):
                print(f"[RSS] æ•°æ®å·²ä¿å­˜åˆ°å­˜å‚¨åç«¯")

                # å¤„ç† RSS æ•°æ®ï¼ˆæŒ‰æ¨¡å¼è¿‡æ»¤ï¼‰å¹¶è¿”å›ç”¨äºåˆå¹¶æ¨é€
                return self._process_rss_data_by_mode(rss_data)
            else:
                print(f"[RSS] æ•°æ®ä¿å­˜å¤±è´¥")
                return None, None, None

        except ImportError as e:
            print(f"[RSS] ç¼ºå°‘ä¾èµ–: {e}")
            print("[RSS] è¯·å®‰è£… feedparser: pip install feedparser")
            return None, None, None
        except Exception as e:
            print(f"[RSS] æŠ“å–å¤±è´¥: {e}")
            return None, None, None

    def _process_rss_data_by_mode(self, rss_data) -> Tuple[Optional[List[Dict]], Optional[List[Dict]], Optional[List[Dict]]]:
        """
        æŒ‰æŠ¥å‘Šæ¨¡å¼å¤„ç† RSS æ•°æ®ï¼Œè¿”å›ä¸çƒ­æ¦œç›¸åŒæ ¼å¼çš„ç»Ÿè®¡ç»“æ„

        ä¸‰ç§æ¨¡å¼ï¼š
        - daily: å½“æ—¥æ±‡æ€»ï¼Œç»Ÿè®¡=å½“å¤©æ‰€æœ‰æ¡ç›®ï¼Œæ–°å¢=æœ¬æ¬¡æ–°å¢æ¡ç›®
        - current: å½“å‰æ¦œå•ï¼Œç»Ÿè®¡=å½“å‰æ¦œå•æ¡ç›®ï¼Œæ–°å¢=æœ¬æ¬¡æ–°å¢æ¡ç›®
        - incremental: å¢é‡æ¨¡å¼ï¼Œç»Ÿè®¡=æ–°å¢æ¡ç›®ï¼Œæ–°å¢=æ— 

        Args:
            rss_data: å½“å‰æŠ“å–çš„ RSSData å¯¹è±¡

        Returns:
            (rss_stats, rss_new_stats, raw_rss_items) å…ƒç»„ï¼š
            - rss_stats: RSS å…³é”®è¯ç»Ÿè®¡åˆ—è¡¨ï¼ˆä¸çƒ­æ¦œ stats æ ¼å¼ä¸€è‡´ï¼‰
            - rss_new_stats: RSS æ–°å¢å…³é”®è¯ç»Ÿè®¡åˆ—è¡¨ï¼ˆä¸çƒ­æ¦œ stats æ ¼å¼ä¸€è‡´ï¼‰
            - raw_rss_items: åŸå§‹ RSS æ¡ç›®åˆ—è¡¨ï¼ˆç”¨äºç‹¬ç«‹å±•ç¤ºåŒºï¼‰
        """
        from trendradar.core.analyzer import count_rss_frequency

        # ä» display.regions.rss ç»Ÿä¸€æ§åˆ¶ RSS åˆ†æå’Œå±•ç¤º
        rss_display_enabled = self.ctx.config.get("DISPLAY", {}).get("REGIONS", {}).get("RSS", True)

        # åŠ è½½å…³é”®è¯é…ç½®
        try:
            word_groups, filter_words, global_filters = self.ctx.load_frequency_words()
        except FileNotFoundError:
            word_groups, filter_words, global_filters = [], [], []

        timezone = self.ctx.timezone
        max_news_per_keyword = self.ctx.config.get("MAX_NEWS_PER_KEYWORD", 0)
        sort_by_position_first = self.ctx.config.get("SORT_BY_POSITION_FIRST", False)

        rss_stats = None
        rss_new_stats = None
        raw_rss_items = None  # åŸå§‹ RSS æ¡ç›®åˆ—è¡¨ï¼ˆç”¨äºç‹¬ç«‹å±•ç¤ºåŒºï¼‰

        # 1. é¦–å…ˆè·å–åŸå§‹æ¡ç›®ï¼ˆç”¨äºç‹¬ç«‹å±•ç¤ºåŒºï¼Œä¸å— display.regions.rss å½±å“ï¼‰
        # æ ¹æ®æ¨¡å¼è·å–åŸå§‹æ¡ç›®
        if self.report_mode == "incremental":
            new_items_dict = self.storage_manager.detect_new_rss_items(rss_data)
            if new_items_dict:
                raw_rss_items = self._convert_rss_items_to_list(new_items_dict, rss_data.id_to_name)
        elif self.report_mode == "current":
            latest_data = self.storage_manager.get_latest_rss_data(rss_data.date)
            if latest_data:
                raw_rss_items = self._convert_rss_items_to_list(latest_data.items, latest_data.id_to_name)
        else:  # daily
            all_data = self.storage_manager.get_rss_data(rss_data.date)
            if all_data:
                raw_rss_items = self._convert_rss_items_to_list(all_data.items, all_data.id_to_name)

        # å¦‚æœ RSS å±•ç¤ºæœªå¯ç”¨ï¼Œè·³è¿‡å…³é”®è¯åˆ†æï¼Œåªè¿”å›åŸå§‹æ¡ç›®ç”¨äºç‹¬ç«‹å±•ç¤ºåŒº
        if not rss_display_enabled:
            return None, None, raw_rss_items

        # 2. è·å–æ–°å¢æ¡ç›®ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
        new_items_dict = self.storage_manager.detect_new_rss_items(rss_data)
        new_items_list = None
        if new_items_dict:
            new_items_list = self._convert_rss_items_to_list(new_items_dict, rss_data.id_to_name)
            if new_items_list:
                print(f"[RSS] æ£€æµ‹åˆ° {len(new_items_list)} æ¡æ–°å¢")

        # 3. æ ¹æ®æ¨¡å¼è·å–ç»Ÿè®¡æ¡ç›®
        if self.report_mode == "incremental":
            # å¢é‡æ¨¡å¼ï¼šç»Ÿè®¡æ¡ç›®å°±æ˜¯æ–°å¢æ¡ç›®
            if not new_items_list:
                print("[RSS] å¢é‡æ¨¡å¼ï¼šæ²¡æœ‰æ–°å¢ RSS æ¡ç›®")
                return None, None, raw_rss_items

            rss_stats, total = count_rss_frequency(
                rss_items=new_items_list,
                word_groups=word_groups,
                filter_words=filter_words,
                global_filters=global_filters,
                new_items=new_items_list,  # å¢é‡æ¨¡å¼æ‰€æœ‰éƒ½æ˜¯æ–°å¢
                max_news_per_keyword=max_news_per_keyword,
                sort_by_position_first=sort_by_position_first,
                timezone=timezone,
                rank_threshold=self.rank_threshold,
                quiet=False,
            )
            if not rss_stats:
                print("[RSS] å¢é‡æ¨¡å¼ï¼šå…³é”®è¯åŒ¹é…åæ²¡æœ‰å†…å®¹")
                # å³ä½¿å…³é”®è¯åŒ¹é…ä¸ºç©ºï¼Œä¹Ÿè¿”å›åŸå§‹æ¡ç›®ç”¨äºç‹¬ç«‹å±•ç¤ºåŒº
                return None, None, raw_rss_items

        elif self.report_mode == "current":
            # å½“å‰æ¦œå•æ¨¡å¼ï¼šç»Ÿè®¡=å½“å‰æ¦œå•æ‰€æœ‰æ¡ç›®
            # raw_rss_items å·²åœ¨å‰é¢è·å–
            if not raw_rss_items:
                print("[RSS] å½“å‰æ¦œå•æ¨¡å¼ï¼šæ²¡æœ‰ RSS æ•°æ®")
                return None, None, None

            rss_stats, total = count_rss_frequency(
                rss_items=raw_rss_items,
                word_groups=word_groups,
                filter_words=filter_words,
                global_filters=global_filters,
                new_items=new_items_list,  # æ ‡è®°æ–°å¢
                max_news_per_keyword=max_news_per_keyword,
                sort_by_position_first=sort_by_position_first,
                timezone=timezone,
                rank_threshold=self.rank_threshold,
                quiet=False,
            )
            if not rss_stats:
                print("[RSS] å½“å‰æ¦œå•æ¨¡å¼ï¼šå…³é”®è¯åŒ¹é…åæ²¡æœ‰å†…å®¹")
                # å³ä½¿å…³é”®è¯åŒ¹é…ä¸ºç©ºï¼Œä¹Ÿè¿”å›åŸå§‹æ¡ç›®ç”¨äºç‹¬ç«‹å±•ç¤ºåŒº
                return None, None, raw_rss_items

            # ç”Ÿæˆæ–°å¢ç»Ÿè®¡
            if new_items_list:
                rss_new_stats, _ = count_rss_frequency(
                    rss_items=new_items_list,
                    word_groups=word_groups,
                    filter_words=filter_words,
                    global_filters=global_filters,
                    new_items=new_items_list,
                    max_news_per_keyword=max_news_per_keyword,
                    sort_by_position_first=sort_by_position_first,
                    timezone=timezone,
                    rank_threshold=self.rank_threshold,
                    quiet=True,
                )

        else:
            # daily æ¨¡å¼ï¼šç»Ÿè®¡=å½“å¤©æ‰€æœ‰æ¡ç›®
            # raw_rss_items å·²åœ¨å‰é¢è·å–
            if not raw_rss_items:
                print("[RSS] å½“æ—¥æ±‡æ€»æ¨¡å¼ï¼šæ²¡æœ‰ RSS æ•°æ®")
                return None, None, None

            rss_stats, total = count_rss_frequency(
                rss_items=raw_rss_items,
                word_groups=word_groups,
                filter_words=filter_words,
                global_filters=global_filters,
                new_items=new_items_list,  # æ ‡è®°æ–°å¢
                max_news_per_keyword=max_news_per_keyword,
                sort_by_position_first=sort_by_position_first,
                timezone=timezone,
                rank_threshold=self.rank_threshold,
                quiet=False,
            )
            if not rss_stats:
                print("[RSS] å½“æ—¥æ±‡æ€»æ¨¡å¼ï¼šå…³é”®è¯åŒ¹é…åæ²¡æœ‰å†…å®¹")
                # å³ä½¿å…³é”®è¯åŒ¹é…ä¸ºç©ºï¼Œä¹Ÿè¿”å›åŸå§‹æ¡ç›®ç”¨äºç‹¬ç«‹å±•ç¤ºåŒº
                return None, None, raw_rss_items

            # ç”Ÿæˆæ–°å¢ç»Ÿè®¡
            if new_items_list:
                rss_new_stats, _ = count_rss_frequency(
                    rss_items=new_items_list,
                    word_groups=word_groups,
                    filter_words=filter_words,
                    global_filters=global_filters,
                    new_items=new_items_list,
                    max_news_per_keyword=max_news_per_keyword,
                    sort_by_position_first=sort_by_position_first,
                    timezone=timezone,
                    rank_threshold=self.rank_threshold,
                    quiet=True,
                )

        return rss_stats, rss_new_stats, raw_rss_items

    def _convert_rss_items_to_list(self, items_dict: Dict, id_to_name: Dict) -> List[Dict]:
        """å°† RSS æ¡ç›®å­—å…¸è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œå¹¶åº”ç”¨æ–°é²œåº¦è¿‡æ»¤ï¼ˆç”¨äºæ¨é€ï¼‰"""
        rss_items = []
        filtered_count = 0
        filtered_details = []  # ç”¨äº DEBUG æ¨¡å¼ä¸‹çš„è¯¦ç»†æ—¥å¿—

        # è·å–æ–°é²œåº¦è¿‡æ»¤é…ç½®
        rss_config = self.ctx.rss_config
        freshness_config = rss_config.get("FRESHNESS_FILTER", {})
        freshness_enabled = freshness_config.get("ENABLED", True)
        default_max_age_days = freshness_config.get("MAX_AGE_DAYS", 3)
        timezone = self.ctx.config.get("TIMEZONE", DEFAULT_TIMEZONE)
        debug_mode = self.ctx.config.get("DEBUG", False)

        # æ„å»º feed_id -> max_age_days çš„æ˜ å°„
        feed_max_age_map = {}
        for feed_cfg in self.ctx.rss_feeds:
            feed_id = feed_cfg.get("id", "")
            max_age = feed_cfg.get("max_age_days")
            if max_age is not None:
                try:
                    feed_max_age_map[feed_id] = int(max_age)
                except (ValueError, TypeError):
                    pass

        for feed_id, items in items_dict.items():
            # ç¡®å®šæ­¤ feed çš„ max_age_days
            max_days = feed_max_age_map.get(feed_id)
            if max_days is None:
                max_days = default_max_age_days

            for item in items:
                # åº”ç”¨æ–°é²œåº¦è¿‡æ»¤ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
                if freshness_enabled and max_days > 0:
                    if item.published_at and not is_within_days(item.published_at, max_days, timezone):
                        filtered_count += 1
                        # è®°å½•è¯¦ç»†ä¿¡æ¯ç”¨äº DEBUG æ¨¡å¼
                        if debug_mode:
                            days_old = calculate_days_old(item.published_at, timezone)
                            feed_name = id_to_name.get(feed_id, feed_id)
                            filtered_details.append({
                                "title": item.title[:50] + "..." if len(item.title) > 50 else item.title,
                                "feed": feed_name,
                                "days_old": days_old,
                                "max_days": max_days,
                            })
                        continue  # è·³è¿‡è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ç« 

                rss_items.append({
                    "title": item.title,
                    "feed_id": feed_id,
                    "feed_name": id_to_name.get(feed_id, feed_id),
                    "url": item.url,
                    "published_at": item.published_at,
                    "summary": item.summary,
                    "author": item.author,
                })

        # è¾“å‡ºè¿‡æ»¤ç»Ÿè®¡
        if filtered_count > 0:
            print(f"[RSS] æ–°é²œåº¦è¿‡æ»¤ï¼šè·³è¿‡ {filtered_count} ç¯‡è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ—§æ–‡ç« ï¼ˆä»ä¿ç•™åœ¨æ•°æ®åº“ä¸­ï¼‰")
            # DEBUG æ¨¡å¼ä¸‹æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if debug_mode and filtered_details:
                print(f"[RSS] è¢«è¿‡æ»¤çš„æ–‡ç« è¯¦æƒ…ï¼ˆå…± {len(filtered_details)} ç¯‡ï¼‰ï¼š")
                for detail in filtered_details[:10]:  # æœ€å¤šæ˜¾ç¤º 10 æ¡
                    days_str = f"{detail['days_old']:.1f}" if detail['days_old'] else "æœªçŸ¥"
                    print(f"  - [{days_str}å¤©å‰] [{detail['feed']}] {detail['title']} (é™åˆ¶: {detail['max_days']}å¤©)")
                if len(filtered_details) > 10:
                    print(f"  ... è¿˜æœ‰ {len(filtered_details) - 10} ç¯‡è¢«è¿‡æ»¤")

        return rss_items

    def _filter_rss_by_keywords(self, rss_items: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨ frequency_words.txt è¿‡æ»¤ RSS æ¡ç›®"""
        try:
            word_groups, filter_words, global_filters = self.ctx.load_frequency_words()
            if word_groups or filter_words or global_filters:
                from trendradar.core.frequency import matches_word_groups
                filtered_items = []
                for item in rss_items:
                    title = item.get("title", "")
                    if matches_word_groups(title, word_groups, filter_words, global_filters):
                        filtered_items.append(item)

                original_count = len(rss_items)
                rss_items = filtered_items
                print(f"[RSS] å…³é”®è¯è¿‡æ»¤åå‰©ä½™ {len(rss_items)}/{original_count} æ¡")

                if not rss_items:
                    print("[RSS] å…³é”®è¯è¿‡æ»¤åæ²¡æœ‰åŒ¹é…å†…å®¹")
                    return []
        except FileNotFoundError:
            # frequency_words.txt ä¸å­˜åœ¨æ—¶è·³è¿‡è¿‡æ»¤
            pass
        return rss_items

    def _generate_rss_html_report(self, rss_items: list, feeds_info: dict) -> str:
        """ç”Ÿæˆ RSS HTML æŠ¥å‘Š"""
        try:
            from trendradar.report.rss_html import render_rss_html_content
            from pathlib import Path

            html_content = render_rss_html_content(
                rss_items=rss_items,
                total_count=len(rss_items),
                feeds_info=feeds_info,
                get_time_func=self.ctx.get_time,
            )

            # ä¿å­˜ HTML æ–‡ä»¶ï¼ˆæ‰å¹³åŒ–ç»“æ„ï¼šoutput/html/æ—¥æœŸ/ï¼‰
            date_folder = self.ctx.format_date()
            time_filename = self.ctx.format_time()
            output_dir = Path("output") / "html" / date_folder
            output_dir.mkdir(parents=True, exist_ok=True)

            file_path = output_dir / f"rss_{time_filename}.html"
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(html_content)

            print(f"[RSS] HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {file_path}")
            return str(file_path)

        except Exception as e:
            print(f"[RSS] ç”Ÿæˆ HTML æŠ¥å‘Šå¤±è´¥: {e}")
            return None

    def _execute_mode_strategy(
        self, mode_strategy: Dict, results: Dict, id_to_name: Dict, failed_ids: List,
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
        raw_rss_items: Optional[List[Dict]] = None,
    ) -> Optional[str]:
        """æ‰§è¡Œæ¨¡å¼ç‰¹å®šé€»è¾‘ï¼Œæ”¯æŒçƒ­æ¦œ+RSSåˆå¹¶æ¨é€

        ç®€åŒ–åçš„é€»è¾‘ï¼š
        - æ¯æ¬¡è¿è¡Œéƒ½ç”Ÿæˆ HTML æŠ¥å‘Šï¼ˆæ—¶é—´æˆ³å¿«ç…§ + latest/{mode}.html + index.htmlï¼‰
        - æ ¹æ®æ¨¡å¼å‘é€é€šçŸ¥
        """
        # è·å–å½“å‰ç›‘æ§å¹³å°IDåˆ—è¡¨
        current_platform_ids = self.ctx.platform_ids

        new_titles = self.ctx.detect_new_titles(current_platform_ids)
        time_info = self.ctx.format_time()
        if self.ctx.config["STORAGE"]["FORMATS"]["TXT"]:
            self.ctx.save_titles(results, id_to_name, failed_ids)
        word_groups, filter_words, global_filters = self.ctx.load_frequency_words()

        html_file = None
        stats = []
        ai_result = None
        title_info = None

        # current æ¨¡å¼éœ€è¦ä½¿ç”¨å®Œæ•´çš„å†å²æ•°æ®
        if self.report_mode == "current":
            analysis_data = self._load_analysis_data()
            if analysis_data:
                (
                    all_results,
                    historical_id_to_name,
                    historical_title_info,
                    historical_new_titles,
                    _,
                    _,
                    _,
                ) = analysis_data

                print(
                    f"currentæ¨¡å¼ï¼šä½¿ç”¨è¿‡æ»¤åçš„å†å²æ•°æ®ï¼ŒåŒ…å«å¹³å°ï¼š{list(all_results.keys())}"
                )

                # ä½¿ç”¨å†å²æ•°æ®å‡†å¤‡ç‹¬ç«‹å±•ç¤ºåŒºæ•°æ®ï¼ˆåŒ…å«å®Œæ•´çš„ title_infoï¼‰
                standalone_data = self._prepare_standalone_data(
                    all_results, historical_id_to_name, historical_title_info, raw_rss_items
                )

                stats, html_file, ai_result = self._run_analysis_pipeline(
                    all_results,
                    self.report_mode,
                    historical_title_info,
                    historical_new_titles,
                    word_groups,
                    filter_words,
                    historical_id_to_name,
                    failed_ids=failed_ids,
                    global_filters=global_filters,
                    rss_items=rss_items,
                    rss_new_items=rss_new_items,
                    standalone_data=standalone_data,
                )

                combined_id_to_name = {**historical_id_to_name, **id_to_name}
                new_titles = historical_new_titles
                id_to_name = combined_id_to_name
                title_info = historical_title_info
                results = all_results
            else:
                print("âŒ ä¸¥é‡é”™è¯¯ï¼šæ— æ³•è¯»å–åˆšä¿å­˜çš„æ•°æ®æ–‡ä»¶")
                raise RuntimeError("æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ï¼šä¿å­˜åç«‹å³è¯»å–å¤±è´¥")
        elif self.report_mode == "daily":
            # daily æ¨¡å¼ï¼šä½¿ç”¨å…¨å¤©ç´¯è®¡æ•°æ®
            analysis_data = self._load_analysis_data()
            if analysis_data:
                (
                    all_results,
                    historical_id_to_name,
                    historical_title_info,
                    historical_new_titles,
                    _,
                    _,
                    _,
                ) = analysis_data

                # ä½¿ç”¨å†å²æ•°æ®å‡†å¤‡ç‹¬ç«‹å±•ç¤ºåŒºæ•°æ®ï¼ˆåŒ…å«å®Œæ•´çš„ title_infoï¼‰
                standalone_data = self._prepare_standalone_data(
                    all_results, historical_id_to_name, historical_title_info, raw_rss_items
                )

                stats, html_file, ai_result = self._run_analysis_pipeline(
                    all_results,
                    self.report_mode,
                    historical_title_info,
                    historical_new_titles,
                    word_groups,
                    filter_words,
                    historical_id_to_name,
                    failed_ids=failed_ids,
                    global_filters=global_filters,
                    rss_items=rss_items,
                    rss_new_items=rss_new_items,
                    standalone_data=standalone_data,
                )

                combined_id_to_name = {**historical_id_to_name, **id_to_name}
                new_titles = historical_new_titles
                id_to_name = combined_id_to_name
                title_info = historical_title_info
                results = all_results
            else:
                # æ²¡æœ‰å†å²æ•°æ®æ—¶ä½¿ç”¨å½“å‰æ•°æ®
                title_info = self._prepare_current_title_info(results, time_info)
                standalone_data = self._prepare_standalone_data(
                    results, id_to_name, title_info, raw_rss_items
                )
                stats, html_file, ai_result = self._run_analysis_pipeline(
                    results,
                    self.report_mode,
                    title_info,
                    new_titles,
                    word_groups,
                    filter_words,
                    id_to_name,
                    failed_ids=failed_ids,
                    global_filters=global_filters,
                    rss_items=rss_items,
                    rss_new_items=rss_new_items,
                    standalone_data=standalone_data,
                )
        else:
            # incremental æ¨¡å¼ï¼šåªä½¿ç”¨å½“å‰æŠ“å–çš„æ•°æ®
            title_info = self._prepare_current_title_info(results, time_info)
            standalone_data = self._prepare_standalone_data(
                results, id_to_name, title_info, raw_rss_items
            )
            stats, html_file, ai_result = self._run_analysis_pipeline(
                results,
                self.report_mode,
                title_info,
                new_titles,
                word_groups,
                filter_words,
                id_to_name,
                failed_ids=failed_ids,
                global_filters=global_filters,
                rss_items=rss_items,
                rss_new_items=rss_new_items,
                standalone_data=standalone_data,
            )

        if html_file:
            print(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_file}")
            print(f"æœ€æ–°æŠ¥å‘Šå·²æ›´æ–°: output/html/latest/{self.report_mode}.html")

        # å‘é€é€šçŸ¥
        if mode_strategy["should_send_notification"]:
            standalone_data = self._prepare_standalone_data(
                results, id_to_name, title_info, raw_rss_items
            )
            self._send_notification_if_needed(
                stats,
                mode_strategy["report_type"],
                self.report_mode,
                failed_ids=failed_ids,
                new_titles=new_titles,
                id_to_name=id_to_name,
                html_file_path=html_file,
                rss_items=rss_items,
                rss_new_items=rss_new_items,
                standalone_data=standalone_data,
                ai_result=ai_result,
                current_results=results,
            )

        # æ‰“å¼€æµè§ˆå™¨ï¼ˆä»…åœ¨éå®¹å™¨ç¯å¢ƒï¼‰
        if self._should_open_browser() and html_file:
            file_url = "file://" + str(Path(html_file).resolve())
            print(f"æ­£åœ¨æ‰“å¼€HTMLæŠ¥å‘Š: {file_url}")
            webbrowser.open(file_url)
        elif self.is_docker_container and html_file:
            print(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆï¼ˆDockerç¯å¢ƒï¼‰: {html_file}")

        return html_file

    def run(self) -> None:
        """æ‰§è¡Œåˆ†ææµç¨‹"""
        try:
            self._initialize_and_check_config()

            mode_strategy = self._get_mode_strategy()

            # æŠ“å–çƒ­æ¦œæ•°æ®
            results, id_to_name, failed_ids = self._crawl_data()

            # æŠ“å– RSS æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œè¿”å›ç»Ÿè®¡æ¡ç›®ã€æ–°å¢æ¡ç›®å’ŒåŸå§‹æ¡ç›®
            rss_items, rss_new_items, raw_rss_items = self._crawl_rss_data()

            # æ‰§è¡Œæ¨¡å¼ç­–ç•¥ï¼Œä¼ é€’ RSS æ•°æ®ç”¨äºåˆå¹¶æ¨é€
            self._execute_mode_strategy(
                mode_strategy, results, id_to_name, failed_ids,
                rss_items=rss_items, rss_new_items=rss_new_items,
                raw_rss_items=raw_rss_items
            )

        except Exception as e:
            print(f"åˆ†ææµç¨‹æ‰§è¡Œå‡ºé”™: {e}")
            if self.ctx.config.get("DEBUG", False):
                raise
        finally:
            # æ¸…ç†èµ„æºï¼ˆåŒ…æ‹¬è¿‡æœŸæ•°æ®æ¸…ç†å’Œæ•°æ®åº“è¿æ¥å…³é—­ï¼‰
            self.ctx.cleanup()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="TrendRadar - çƒ­ç‚¹æ–°é—»èšåˆä¸åˆ†æå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
çŠ¶æ€ç®¡ç†å‘½ä»¤:
  --show-push-status     æ˜¾ç¤ºæ¨é€çŠ¶æ€ï¼ˆçª—å£é…ç½®ã€ä»Šæ—¥æ˜¯å¦å·²æ¨é€ï¼‰
  --show-ai-status       æ˜¾ç¤º AI åˆ†æçŠ¶æ€
  --reset-push-state     é‡ç½®ä»Šæ—¥æ¨é€çŠ¶æ€ï¼ˆå…è®¸é‡æ–°æ¨é€ï¼‰
  --reset-ai-state       é‡ç½®ä»Šæ—¥ AI åˆ†æçŠ¶æ€
  --force-push           å¿½ç•¥ once_per_day é™åˆ¶ï¼Œå¼ºåˆ¶æ¨é€

ç¤ºä¾‹:
  python -m trendradar                    # æ­£å¸¸è¿è¡Œ
  python -m trendradar --show-push-status # æŸ¥çœ‹æ¨é€çŠ¶æ€
  python -m trendradar --reset-push-state # é‡ç½®æ¨é€çŠ¶æ€åå†è¿è¡Œ
  python -m trendradar --force-push       # å¼ºåˆ¶æ¨é€ï¼ˆå¿½ç•¥ä»Šæ—¥å·²æ¨é€é™åˆ¶ï¼‰
"""
    )
    parser.add_argument(
        "--show-push-status",
        action="store_true",
        help="æ˜¾ç¤ºæ¨é€çŠ¶æ€ä¿¡æ¯"
    )
    parser.add_argument(
        "--show-ai-status",
        action="store_true",
        help="æ˜¾ç¤º AI åˆ†æçŠ¶æ€ä¿¡æ¯"
    )
    parser.add_argument(
        "--reset-push-state",
        action="store_true",
        help="é‡ç½®ä»Šæ—¥æ¨é€çŠ¶æ€"
    )
    parser.add_argument(
        "--reset-ai-state",
        action="store_true",
        help="é‡ç½®ä»Šæ—¥ AI åˆ†æçŠ¶æ€"
    )
    parser.add_argument(
        "--force-push",
        action="store_true",
        help="å¿½ç•¥ once_per_day é™åˆ¶ï¼Œå¼ºåˆ¶æ¨é€"
    )
    parser.add_argument(
        "--force-ai",
        action="store_true",
        help="å¿½ç•¥ once_per_day é™åˆ¶ï¼Œå¼ºåˆ¶ AI åˆ†æ"
    )

    args = parser.parse_args()

    debug_mode = False
    try:
        # å…ˆåŠ è½½é…ç½®
        config = load_config()

        # å¤„ç†çŠ¶æ€æŸ¥çœ‹/é‡ç½®å‘½ä»¤
        if args.show_push_status or args.show_ai_status or args.reset_push_state or args.reset_ai_state:
            _handle_status_commands(config, args)
            return

        # è®¾ç½®å¼ºåˆ¶æ¨é€æ ‡å¿—
        if args.force_push:
            config["_FORCE_PUSH"] = True
            print("[CLI] å·²å¯ç”¨å¼ºåˆ¶æ¨é€æ¨¡å¼ï¼Œå°†å¿½ç•¥ once_per_day é™åˆ¶")

        if args.force_ai:
            config["_FORCE_AI"] = True
            print("[CLI] å·²å¯ç”¨å¼ºåˆ¶ AI åˆ†ææ¨¡å¼ï¼Œå°†å¿½ç•¥ once_per_day é™åˆ¶")

        version_url = config.get("VERSION_CHECK_URL", "")
        configs_version_url = config.get("CONFIGS_VERSION_CHECK_URL", "")

        # ç»Ÿä¸€ç‰ˆæœ¬æ£€æŸ¥ï¼ˆç¨‹åºç‰ˆæœ¬ + é…ç½®æ–‡ä»¶ç‰ˆæœ¬ï¼Œåªè¯·æ±‚ä¸€æ¬¡è¿œç¨‹ï¼‰
        need_update = False
        remote_version = None
        if version_url:
            need_update, remote_version = check_all_versions(version_url, configs_version_url)

        # å¤ç”¨å·²åŠ è½½çš„é…ç½®ï¼Œé¿å…é‡å¤åŠ è½½
        analyzer = NewsAnalyzer(config=config)

        # è®¾ç½®æ›´æ–°ä¿¡æ¯ï¼ˆå¤ç”¨å·²è·å–çš„è¿œç¨‹ç‰ˆæœ¬ï¼Œä¸å†é‡å¤è¯·æ±‚ï¼‰
        if analyzer.is_github_actions and need_update and remote_version:
            analyzer.update_info = {
                "current_version": __version__,
                "remote_version": remote_version,
            }

        # è·å– debug é…ç½®
        debug_mode = analyzer.ctx.config.get("DEBUG", False)
        analyzer.run()
    except FileNotFoundError as e:
        print(f"âŒ é…ç½®æ–‡ä»¶é”™è¯¯: {e}")
        print("\nè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
        print("  â€¢ config/config.yaml")
        print("  â€¢ config/frequency_words.txt")
        print("\nå‚è€ƒé¡¹ç›®æ–‡æ¡£è¿›è¡Œæ­£ç¡®é…ç½®")
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        if debug_mode:
            raise


def _handle_status_commands(config: Dict, args) -> None:
    """å¤„ç†çŠ¶æ€æŸ¥çœ‹/é‡ç½®å‘½ä»¤"""
    from trendradar.context import AppContext

    ctx = AppContext(config)
    push_manager = ctx.create_push_manager()

    print("=" * 60)
    print(f"TrendRadar v{__version__} çŠ¶æ€ä¿¡æ¯")
    print("=" * 60)

    # æ˜¾ç¤ºæ¨é€çŠ¶æ€
    if args.show_push_status:
        push_window_config = config.get("PUSH_WINDOW", {})
        status = push_manager.get_push_status(push_window_config)
        print("\nğŸ“¤ æ¨é€çŠ¶æ€:")
        print(f"  å½“å‰æ—¶é—´: {status['current_time']} ({status['timezone']})")
        print(f"  å½“å‰æ—¥æœŸ: {status['current_date']}")
        print(f"  çª—å£æ§åˆ¶: {'å¯ç”¨' if status['enabled'] else 'æœªå¯ç”¨'}")
        if status['enabled']:
            print(f"  çª—å£æ—¶é—´: {status['window_start']} - {status['window_end']}")
            print(f"  å½“å‰åœ¨çª—å£å†…: {'æ˜¯ âœ…' if status.get('in_window') else 'å¦ âŒ'}")
            print(f"  æ¯å¤©åªæ¨ä¸€æ¬¡: {'æ˜¯' if status.get('once_per_day') else 'å¦'}")
            if status.get('once_per_day'):
                executed = status.get('executed_today', False)
                print(f"  ä»Šæ—¥å·²æ¨é€: {'æ˜¯ âš ï¸' if executed else 'å¦ âœ…'}")

    # æ˜¾ç¤º AI åˆ†æçŠ¶æ€
    if args.show_ai_status:
        ai_window_config = config.get("AI_ANALYSIS", {}).get("ANALYSIS_WINDOW", {})
        status = push_manager.get_ai_analysis_status(ai_window_config)
        print("\nğŸ¤– AI åˆ†æçŠ¶æ€:")
        print(f"  å½“å‰æ—¶é—´: {status['current_time']} ({status['timezone']})")
        print(f"  å½“å‰æ—¥æœŸ: {status['current_date']}")
        print(f"  çª—å£æ§åˆ¶: {'å¯ç”¨' if status['enabled'] else 'æœªå¯ç”¨'}")
        if status['enabled']:
            print(f"  çª—å£æ—¶é—´: {status['window_start']} - {status['window_end']}")
            print(f"  å½“å‰åœ¨çª—å£å†…: {'æ˜¯ âœ…' if status.get('in_window') else 'å¦ âŒ'}")
            print(f"  æ¯å¤©åªåˆ†æä¸€æ¬¡: {'æ˜¯' if status.get('once_per_day') else 'å¦'}")
            if status.get('once_per_day'):
                executed = status.get('executed_today', False)
                print(f"  ä»Šæ—¥å·²åˆ†æ: {'æ˜¯ âš ï¸' if executed else 'å¦ âœ…'}")

    # é‡ç½®æ¨é€çŠ¶æ€
    if args.reset_push_state:
        print("\nğŸ”„ æ­£åœ¨é‡ç½®æ¨é€çŠ¶æ€...")
        if push_manager.reset_push_state():
            print("  âœ… æ¨é€çŠ¶æ€å·²é‡ç½®")
        else:
            print("  âŒ é‡ç½®å¤±è´¥")

    # é‡ç½® AI åˆ†æçŠ¶æ€
    if args.reset_ai_state:
        print("\nğŸ”„ æ­£åœ¨é‡ç½® AI åˆ†æçŠ¶æ€...")
        if push_manager.reset_ai_analysis_state():
            print("  âœ… AI åˆ†æçŠ¶æ€å·²é‡ç½®")
        else:
            print("  âŒ é‡ç½®å¤±è´¥")

    print("=" * 60)

    # æ¸…ç†èµ„æº
    ctx.cleanup()


if __name__ == "__main__":
    main()
